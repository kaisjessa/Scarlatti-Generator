{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras) (1.14.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras) (1.0.5)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras) (1.0.6)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.6.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.14.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.6.2)\n",
      "Requirement already satisfied: html5lib==0.9999999 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (0.9999999)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (2.6.11)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: bleach==1.5.0 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (1.5.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from protobuf>=3.4.0->tensorflow) (39.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.14.3)\n",
      "Requirement already satisfied: music21 in c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (5.1.0)\n",
      "Collecting pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement pickle (from versions: )\n",
      "No matching distribution found for pickle\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install music21\n",
    "!pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing data/scarlatti_midi\\K001.MID\n",
      "Parsing data/scarlatti_midi\\K002.MID\n",
      "Parsing data/scarlatti_midi\\K003.MID\n",
      "Parsing data/scarlatti_midi\\K004.MID\n",
      "Parsing data/scarlatti_midi\\K005.MID\n",
      "Parsing data/scarlatti_midi\\K006.MID\n",
      "Parsing data/scarlatti_midi\\K007.MID\n",
      "Parsing data/scarlatti_midi\\K008.MID\n",
      "Parsing data/scarlatti_midi\\K009.MID\n",
      "Parsing data/scarlatti_midi\\K010.MID\n",
      "Parsing data/scarlatti_midi\\K011.MID\n",
      "Parsing data/scarlatti_midi\\K012.MID\n",
      "Parsing data/scarlatti_midi\\K013.MID\n",
      "Parsing data/scarlatti_midi\\K014.MID\n",
      "Parsing data/scarlatti_midi\\K015.MID\n",
      "Parsing data/scarlatti_midi\\K016.MID\n",
      "Parsing data/scarlatti_midi\\K017.MID\n",
      "Parsing data/scarlatti_midi\\K018.MID\n",
      "Parsing data/scarlatti_midi\\K019.MID\n",
      "Parsing data/scarlatti_midi\\K020.MID\n",
      "Parsing data/scarlatti_midi\\K021.MID\n",
      "Parsing data/scarlatti_midi\\K022.MID\n",
      "Parsing data/scarlatti_midi\\K023.MID\n",
      "Parsing data/scarlatti_midi\\K024.MID\n",
      "Parsing data/scarlatti_midi\\K025.MID\n",
      "Parsing data/scarlatti_midi\\K026.MID\n",
      "Parsing data/scarlatti_midi\\K027.MID\n",
      "Parsing data/scarlatti_midi\\K028.MID\n",
      "Parsing data/scarlatti_midi\\K029.MID\n",
      "Parsing data/scarlatti_midi\\K030.MID\n",
      "Parsing data/scarlatti_midi\\K031.MID\n",
      "Parsing data/scarlatti_midi\\K032.MID\n",
      "Parsing data/scarlatti_midi\\K033.MID\n",
      "Parsing data/scarlatti_midi\\K034.MID\n",
      "Parsing data/scarlatti_midi\\K035.MID\n",
      "Parsing data/scarlatti_midi\\K036.MID\n",
      "Parsing data/scarlatti_midi\\K037.MID\n",
      "Parsing data/scarlatti_midi\\K038.MID\n",
      "Parsing data/scarlatti_midi\\K039.MID\n",
      "Parsing data/scarlatti_midi\\K040.MID\n",
      "Parsing data/scarlatti_midi\\K041.MID\n",
      "Parsing data/scarlatti_midi\\K042.MID\n",
      "Parsing data/scarlatti_midi\\K043.MID\n",
      "Parsing data/scarlatti_midi\\K044.MID\n",
      "Parsing data/scarlatti_midi\\K045.MID\n",
      "Parsing data/scarlatti_midi\\K046.MID\n",
      "Parsing data/scarlatti_midi\\K047.MID\n",
      "Parsing data/scarlatti_midi\\K048.MID\n",
      "Parsing data/scarlatti_midi\\K049.MID\n",
      "Parsing data/scarlatti_midi\\K050.MID\n",
      "45830\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "from music21 import converter, instrument, note, chord\n",
    "\n",
    "#returns character sequence from midi folder\n",
    "def midi_to_text(file_path, num_files=555):\n",
    "\t#array of characters representing notes\n",
    "\tnotes = []\n",
    "\t#go through all midi files in folder\n",
    "\ti = 1\n",
    "\tfor file in glob.glob(file_path):\n",
    "\t\tif(i > num_files):\n",
    "\t\t\treturn(notes)\n",
    "\t\ti += 1\n",
    "\t\t#read the file\n",
    "\t\tmidi = converter.parse(file)\n",
    "\t\t#current notes\n",
    "\t\tnotes_to_parse = None\n",
    "\t\tnotes_to_parse = midi.flat\n",
    "\t\t#print([e for e in midi.flat])\n",
    "\t\t#add notes and chords to array\n",
    "\t\tfor element in notes_to_parse:\n",
    "\t\t\tif isinstance(element, note.Note):\n",
    "\t\t\t\tnotes.append(str(element.pitch))\n",
    "\t\t\telif isinstance(element, chord.Chord):\n",
    "\t\t\t\tnotes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\t\t\telif isinstance(element, note.Rest):\n",
    "\t\t\t\tnotes.append(\" rest\")\n",
    "\t\tprint(\"Parsing %s\" % file)\n",
    "\t#return array\n",
    "\treturn(notes)\n",
    "\n",
    "out = midi_to_text(\"data/scarlatti_midi/*.MID\", 50)\n",
    "print(len(out))\n",
    "with open('data/models/training_data.pkl', 'wb') as f:\n",
    "    pickle.dump([out], f)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kais jessa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45830\n",
      "Unique chars: 249\n",
      "Text length: 45830\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import pickle\n",
    "\n",
    "#open text file with text\n",
    "with open('data/models/training_data.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    text = pickle.load(f)\n",
    "text = text[0]\n",
    "print(len(text))\n",
    "\n",
    "#sort list of unique characters in text\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "#dictionary mapping chars to ints\n",
    "char_to_int = {char:n for n,char in enumerate(chars)}\n",
    "#dictionary mapping ints to chars\n",
    "int_to_char = {n:char for n,char in enumerate(chars)}\n",
    "\n",
    "#training and target lists\n",
    "X,y = [],[]\n",
    "text_length = len(text)\n",
    "#length of string given to NN to make prediction\n",
    "str_length = 50\n",
    "print(\"Unique chars:\", len(chars))\n",
    "print(\"Text length:\", text_length)\n",
    "#loop through text\n",
    "for i in range(0, text_length - str_length, 1):\n",
    "    #add a list of length str_length to training data\n",
    "    X.append([char_to_int[c] for c in text[i : i + str_length]])\n",
    "    #add the next character in the sequence to target list\n",
    "    #y[n] will have the character than comes after x[n][str_length-1]\n",
    "    #we want the NN to predict the next letter based on previous letters\n",
    "    y.append(char_to_int[text[i + str_length]])\n",
    "\n",
    "#reshape training data for the NN\n",
    "X_2 = np.reshape(X, (len(X), str_length, 1))\n",
    "#normalize the training data so that all values are between 0 and 1\n",
    "X_2 = X_2 / float(len(chars))\n",
    "#convert Y to a one-hot array\n",
    "y_2 = np_utils.to_categorical(y)\n",
    "\n",
    "with open('data/models/processed_data.pkl', 'wb') as f:\n",
    "    pickle.dump([X, X_2, y, y_2, char_to_int, int_to_char, chars], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f3eb938cd0d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data/models/new_current_model.h5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mtensorboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"logs/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;31m#tensorboard --logdir=logs/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pickle\n",
    "from time import time\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "#from data_processing import *\n",
    "\n",
    "with open('data/models/processed_data.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    _, X_2, _, y_2, _, _, _ = pickle.load(f)\n",
    "\n",
    "#Keras NN\n",
    "model = Sequential()\n",
    "#add long short term memory cell\n",
    "#output is 256 units (length), input_shape is (number_of_inputs, input_length), return full sequence\n",
    "model.add(LSTM(256, input_shape=(X_2.shape[1], X_2.shape[2]), return_sequences=True)) #layer 1\n",
    "#account for overfitting\n",
    "model.add(Dropout(0.2))\n",
    "#add another LSTM cell (layer 2)\n",
    "model.add(LSTM(256, return_sequences=False))\n",
    "#account for overfitting\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Fully connected (dense) output layer\n",
    "model.add(Dense(y_2.shape[1], activation='softmax')) #layer 4\n",
    "\n",
    "#minimize loss\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "print(\"Model compiled\")\n",
    "\n",
    "#save models after every epoch if the loss improves\n",
    "filepath = \"data/models/new_current_model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=2, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "#tensorboard --logdir=logs/\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "#train the model\n",
    "history = model.fit(X_2, y_2, epochs=128, batch_size=64, callbacks=callbacks_list)\n",
    "#save the model\n",
    "model.save(\"data/models/5_test_model.h5\")\n",
    "print(\"Training Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import keras.models\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "import pickle, sys\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "#from data_preprocessing import *\n",
    "\n",
    "def text_to_midi(prediction_array):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_array:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Harpsichord()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "\n",
    "        # pattern is a rest\n",
    "        elif(pattern == \" rest\"):\n",
    "            new_note = note.Rest()\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Harpsichord()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        #pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Harpsichord()\n",
    "            output_notes.append(new_note)\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "    return output_notes\n",
    "\n",
    "with open('data/models/processed_data.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    X, _, y, _, chat_to_int, int_to_char, chars = pickle.load(f)\n",
    "\n",
    "with open('data/models/training_data.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    text = pickle.load(f)\n",
    "\n",
    "text = text[0]\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "#load model\n",
    "model = keras.models.load_model(\"data/models/3_test_model.h5\")\n",
    "\n",
    "#sample_char = \"\" if len(sys.argv) < 2 else sys.argv[1]\n",
    "#take an array of inputs\n",
    "\n",
    "def check_model():\n",
    "    output_array = []\n",
    "    #random starting point from training data for generation\n",
    "    int_train = X[random.randint(0, len(X))]\n",
    "    #convert starting point back to characters\n",
    "    chars_array = [int_to_char[n] for n in int_train]\n",
    "\n",
    "    #number of characters to generate\n",
    "    for i in range(500):\n",
    "        #reshape data to feed to NN\n",
    "        x = np.reshape(int_train, (1, len(int_train), 1))\n",
    "        #normalize for NN\n",
    "        x = x / float(len(chars))\n",
    "\n",
    "        #the prediction is the index of the next character index\n",
    "        #argmax takes the highest number in the onehot array\n",
    "        int_prediction = np.argmax(model.predict(x, verbose=0))\n",
    "\n",
    "        #append prediction to string array for output\n",
    "        chars_array.append(int_to_char[int_prediction])\n",
    "        output_array.append(int_to_char[int_prediction])\n",
    "\n",
    "        #append index to index array\n",
    "        int_train.append(int_prediction)\n",
    "        #drop first element for next iteration\n",
    "        int_train = int_train[1:]\n",
    "\n",
    "    return(output_array)\n",
    "\n",
    "music_text = check_model()\n",
    "print(music_text)\n",
    "music_midi = text_to_midi(music_text)\n",
    "midi_stream = stream.Stream(music_midi)\n",
    "midi_stream.write('midi', fp='data/005_model_output.mid')\n",
    "print(\"MIDI saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
